{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing Data\n",
    "* Standardization is a preprocessing method used to transform continous data to make it look normally distributed\n",
    "* In scikit-learn, this is often a necessary step, because many models assume that the data you're training on is normally distributed.\n",
    "* Two standardization methods: Log normalization and Feature scaling\n",
    "* Standardization medthods are applied to continous numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to standardize\n",
    "* Data features have high variance\n",
    "* Data features are continuous and on different scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# making data frame from csv file \n",
    "wine = pd.read_csv(\"wine.csv\") \n",
    "X = wine.drop([\"Type\"],axis=1)\n",
    "y = wine[\"Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Log Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log normalization is a method for standardizing the data when the data have a particular column with high variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alcohol                             0.659062\n",
       "Malic acid                          1.248015\n",
       "Ash                                 0.075265\n",
       "Alcalinity of ash                  11.152686\n",
       "Magnesium                         203.989335\n",
       "Total phenols                       0.391690\n",
       "Flavanoids                          0.997719\n",
       "Nonflavanoid phenols                0.015489\n",
       "Proanthocyanins                     0.327595\n",
       "Color intensity                     5.374449\n",
       "Hue                                 0.052245\n",
       "OD280/OD315 of diluted wines        0.504086\n",
       "Proline                         99166.717355\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Normalization\n",
    "import numpy as np\n",
    "X_norm = X.copy()\n",
    "X_norm['Proline'] = np.log(X_norm['Proline'])\n",
    "X_norm['Magnesium'] = np.log(X_norm['Magnesium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol                          0.659062\n",
      "Malic acid                       1.248015\n",
      "Ash                              0.075265\n",
      "Alcalinity of ash               11.152686\n",
      "Magnesium                        0.018667\n",
      "Total phenols                    0.391690\n",
      "Flavanoids                       0.997719\n",
      "Nonflavanoid phenols             0.015489\n",
      "Proanthocyanins                  0.327595\n",
      "Color intensity                  5.374449\n",
      "Hue                              0.052245\n",
      "OD280/OD315 of diluted wines     0.504086\n",
      "Proline                          0.172314\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_norm.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Scaling\n",
    "* Scaling is a standardization method which is useful when your dataset contains continuous featuures that are on different scales\n",
    "* Feature scaling transforms the features in your dataset have a mean of zero and a variance of one. Transforms to approximately normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Ash  Alcalinity of ash   Magnesium\n",
      "count  178.000000         178.000000  178.000000\n",
      "mean     2.366517          19.494944   99.741573\n",
      "std      0.274344           3.339564   14.282484\n",
      "min      1.360000          10.600000   70.000000\n",
      "25%      2.210000          17.200000   88.000000\n",
      "50%      2.360000          19.500000   98.000000\n",
      "75%      2.557500          21.500000  107.000000\n",
      "max      3.230000          30.000000  162.000000\n",
      "                  0             1             2\n",
      "count  1.780000e+02  1.780000e+02  1.780000e+02\n",
      "mean  -8.657245e-16 -1.160121e-16 -1.995907e-17\n",
      "std    1.002821e+00  1.002821e+00  1.002821e+00\n",
      "min   -3.679162e+00 -2.671018e+00 -2.088255e+00\n",
      "25%   -5.721225e-01 -6.891372e-01 -8.244151e-01\n",
      "50%   -2.382132e-02  1.518295e-03 -1.222817e-01\n",
      "75%    6.981085e-01  6.020883e-01  5.096384e-01\n",
      "max    3.156325e+00  3.154511e+00  4.371372e+00\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import StandardScaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Take a subset of the DataFrame you want to scale \n",
    "wine_subset = wine[['Ash','Alcalinity of ash','Magnesium']]\n",
    "print(wine_subset.describe())\n",
    "\n",
    "# Apply the scaler to the DataFrame subset\n",
    "wine_subset_scaled = ss.fit_transform(wine_subset)\n",
    "\n",
    "print(pd.DataFrame(wine_subset_scaled).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create the scaling method.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Apply the scaling method to the dataset used for modeling.\n",
    "X_scaled = ss.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data.\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Score the model on the test data.\n",
    "print(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
